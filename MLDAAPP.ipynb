{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "PLM0XTOWjYKF",
        "QWhLAng7xzFh",
        "RwDHFfi-vegr",
        "0-uLUVoQvnla",
        "D8X67o1GeGLA",
        "ikybQvh_K2YJ",
        "Ux6ogRKmLp9s",
        "bJquvCpoLNES",
        "fDs9dYv9xwBk",
        "B3GuyWsv7GGc",
        "uNMSSwAj-9ht",
        "HqlxiJ2sSisG",
        "DeRsCu35jPyz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Key notes: Please refer to \"https://github.com/ganamir/MLDAAPP\" for more information!\n",
        "\n",
        "WARNING! Keep in mind to run these scripts on a cloud service such as Google Colab!\n",
        "Unless you possess server level computational resources you may overheat and damage your computer parts! Machine Learning based Computer Vision is a far more computationally intensive process than a typical computer vision program."
      ],
      "metadata": {
        "id": "JS6ugHhAy2Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install & Import all of dependancies and functions:**"
      ],
      "metadata": {
        "id": "PLM0XTOWjYKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhrgvItjVgbk"
      },
      "outputs": [],
      "source": [
        "#Connect Google Drive for ease of use when transfering/uploading files:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Download & Upload Package into the local environment:\n",
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install av\n",
        "!pip install ffmpeg\n",
        "!pip install supervision\n",
        "!pip install PIL\n",
        "#!pip install certifi\n",
        "#!pip install cycler\n",
        "!pip install pyparsing\n",
        "!pip install pyheif\n",
        "import pyheif\n",
        "import csv\n",
        "from moviepy.editor import *\n",
        "import supervision as sv\n",
        "import math\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import PIL.ImageDraw as ImageDraw\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import cv2\n",
        "import ffmpeg\n",
        "import av\n",
        "import av.datasets\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import random\n",
        "from numpy import loadtxt\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from pandas.io.parsers.readers import RangeIndex\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "!git clone https://github.com/ultralytics/ultralytics.git\n",
        "display.clear_output()\n",
        "\n",
        "#Functions:\n",
        "def video_editing(input, t0, t1, fps, spd, w):\n",
        "  #Video Modification:\n",
        "  SOURCE_VIDEO_PATH = input\n",
        "  #Modify Video Length, Framerate, & Speed:\n",
        "  clip1 = VideoFileClip(SOURCE_VIDEO_PATH)\n",
        "  clip1 = clip1.subclip(t0,t1)\n",
        "  clip1_resol = clip1.resize(width = w)\n",
        "  new_clip2 = clip1_resol.set_fps(fps)\n",
        "  new_clip3 = new_clip2.fx(vfx.speedx, spd)\n",
        "  #Save the File:\n",
        "  file_path = os.path.dirname(SOURCE_VIDEO_PATH)\n",
        "  file_name = os.path.basename(SOURCE_VIDEO_PATH)\n",
        "  file_name = os.path.splitext(file_name)[0]\n",
        "  starting_value = 1\n",
        "  while True:\n",
        "    folder_name = file_name + str(starting_value)\n",
        "    folder_path = os.path.join(file_path, folder_name)\n",
        "    if not os.path.exists(folder_path):\n",
        "      os.makedirs(folder_path)\n",
        "      break\n",
        "    starting_value += 1\n",
        "  new_clip3.write_videofile(folder_path+\"/\"+file_name+\".mp4\" , codec = \"libx264\")\n",
        "  global global_video\n",
        "  global_video = folder_path+\"/\"+file_name+\".mp4\"\n",
        "\n",
        "def save_to_csv(filename, column_name, data):\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([column_name])\n",
        "        for value in data:\n",
        "            writer.writerow([value])\n",
        "\n",
        "def draw_dots(img,x,y):\n",
        "  %matplotlib inline\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(img)\n",
        "  plt.plot(x, y, marker = 'o', markersize = 2)\n",
        "\n",
        "def draw_lines(img,x1,y1,x2,y2):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(img)\n",
        "  xlp, ylp = [x1,x2],[y1,y2]\n",
        "  plt.plot(xlp,ylp,marker = 'o', markersize = 2)\n",
        "\n",
        "def draw_polygons(img,x1,y1,x2,y2,x3,y3,x4,y4):\n",
        "  %matplotlib inline\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(img)\n",
        "\n",
        "  coords1 = [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]\n",
        "  coords1.append(coords1[0])\n",
        "  xs, ys = zip(*coords1)\n",
        "  for x,y in zip(xs,ys):\n",
        "    label = \"{:.2f}\".format(y)\n",
        "    plt.annotate(label,\n",
        "                (x,y),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext = (0,10),\n",
        "                ha ='center')\n",
        "  plt.plot(xs,ys)\n",
        "\n",
        "def area_by_shoelace(x, y):\n",
        "  \"Assumes x,y points go around the polygon in one direction\"\n",
        "  return abs( sum(i * j for i, j in zip(x,y[1:] + y[:1]))\n",
        "               -sum(i * j for i, j in zip(x[1:] + x[:1], y))) / 2\n",
        "\n",
        "# Define your function\n",
        "def process_file(file_path, parent_directory):\n",
        "\n",
        "      predict_folder_path = os.path.join(os.path.dirname(file_path), 'predict')\n",
        "      if os.path.exists(predict_folder_path) and os.path.isdir(predict_folder_path):\n",
        "          print(f\"Skipping {file_path} as it has a 'predict' folder.\")\n",
        "          return\n",
        "\n",
        "      ID = []\n",
        "      Names = []\n",
        "      XYXY = []\n",
        "      Masks = []\n",
        "      Num_Frames = []\n",
        "      n = []\n",
        "      Class = []\n",
        "\n",
        "      results = model.track(file_path,tracker=\"/content/ultralytics/ultralytics/cfg/trackers/botsort.yaml\", project = file_dir, save_frames = False, save=True, persist = True, iou = 0.7, conf = 0.5, stream = True, save_conf = True, show_conf = False, show_labels = True, )\n",
        "      for results in results:\n",
        "        boxes = results.boxes\n",
        "        masks = results.masks\n",
        "        probs = results.probs\n",
        "        id = results.boxes.id\n",
        "        n.append(len(boxes))\n",
        "        for i in range(len(results)):\n",
        "          for x in range(len(results[i].boxes.xyxy.cpu().numpy())):\n",
        "            try:\n",
        "              if results.boxes is not None:\n",
        "                ID.append(results[i][x].boxes.id.cpu().numpy())\n",
        "              else:\n",
        "                ID.append(None)\n",
        "              if XYXY is not None:\n",
        "                XYXY.append(results[i][x].boxes.xyxy.cpu().numpy())\n",
        "              else:\n",
        "                pass\n",
        "              if Masks is not None:\n",
        "                Masks.append(results[i][x].masks.xy)\n",
        "              else:\n",
        "                pass\n",
        "              if Names is not None:\n",
        "                Names.append(results[i][x].names)\n",
        "              else:\n",
        "                pass\n",
        "            except AttributeError:\n",
        "              pass\n",
        "      #Set the analyzed video as a photo frame to draw on:\n",
        "      algimg = results[0].orig_img\n",
        "                          #______________________________________________________________________#____________________________________________________#Extract general information from ML algorithm:\n",
        "      df = pd.DataFrame(ID, columns = [\"ID\"])\n",
        "      df71234848 = np.vstack(Names)\n",
        "      df71234848 = pd.DataFrame(df71234848, columns = ['Object_Name'])\n",
        "      df2 = np.vstack(XYXY)\n",
        "      df3 = pd.DataFrame(df2, columns = (\"X1\",\"Y1\",\"X2\",\"Y2\"))\n",
        "      df5 = pd.concat([df,df3], axis = 1)\n",
        "      df5432 = pd.DataFrame(Masks, columns = [\"Masks0\"])\n",
        "\n",
        "      # df5 = pd.concat([df,df3,df5432], axis = 1)\n",
        "      # If used segmentation model ^Un-hash this to add Mask Coordinates to your DataFrame, be careful as highly dimensional objects may cause issues in your output .csv file\n",
        "\n",
        "      df5 = pd.concat([df71234848, df5], axis = 1)\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#Assign Frame Numbers:\n",
        "\n",
        "      df5['Frame_num'] = df5.groupby(['ID']).cumcount()+1\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Distance away from point q\n",
        "      #Object_ID centroid coordinate:\n",
        "      Centroid = []\n",
        "      for x in range(len(df5)):\n",
        "        Centroid.append([((df5['X1'][x]+df5['X2'][x])/2),((df5['Y1'][x]+df5['Y2'][x])/2)])\n",
        "\n",
        "      Centroid_df = pd.DataFrame(Centroid, columns = ['Centroid_X','Centroid_Y'])\n",
        "      df5 = pd.concat([df5,Centroid_df],axis=1)\n",
        "\n",
        "      #Object_ID distance away from point q:\n",
        "\n",
        "      distance = []\n",
        "      if \"q\" in locals():\n",
        "        for j in range(len(df5['Centroid_X'])):\n",
        "          distance.append(math.sqrt( ((df5['Centroid_X'][j]-q[0])**2)+((df5['Centroid_Y'][j]-q[1])**2)))\n",
        "        distance_df = pd.DataFrame(distance, columns = ['ID_Q_Distance'])\n",
        "        df5 = pd.concat([df5,distance_df], axis = 1)\n",
        "\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Distance away from initial position: (FiX THE LOOP)\n",
        "\n",
        "      #Adding Origin Distance to the correct ID:\n",
        "      IDD_LIST = df5.ID.unique()\n",
        "      Fly_ID_list = []\n",
        "      Fly_ID_list.append(df5[df5['Frame_num'] == 1])\n",
        "      Fly_ID_df = df5[['ID','Frame_num','Centroid_X','Centroid_Y']]\n",
        "      Fly_ID_df = Fly_ID_df[Fly_ID_df['Frame_num'] == 1]\n",
        "      Org_X = Fly_ID_df.Centroid_X.values.tolist()\n",
        "      Org_Y = Fly_ID_df.Centroid_Y.values.tolist()\n",
        "      centroid_origin = [(x, y) for x, y in zip(Org_X, Org_Y)]\n",
        "\n",
        "      origin_index = 0\n",
        "      for h in df5.ID.unique():\n",
        "          fly_df = df5[df5['ID'] == h]\n",
        "          for index, row in fly_df.iterrows():\n",
        "              df5.loc[index, 'Origin_X'] = centroid_origin[origin_index][0]\n",
        "              df5.loc[index, 'Origin_Y'] = centroid_origin[origin_index][1]\n",
        "          origin_index += 1\n",
        "\n",
        "      orig_distance = []\n",
        "      for j in range(len(df5['Centroid_X'])):\n",
        "        orig_distance.append(math.sqrt( ((df5['Centroid_X'][j]-df5['Origin_X'][j])**2)+((df5['Centroid_Y'][j]-df5['Origin_Y'][j])**2)))\n",
        "      orig_distance_df = pd.DataFrame(orig_distance, columns = ['ID_Orig_Distance'])\n",
        "      df5 = pd.concat([df5,orig_distance_df], axis = 1)\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Total Walk Distance by ID / Total Walk Distance by Frame:\n",
        "\n",
        "      df10293847123948712349812374981234 = pd.DataFrame()\n",
        "      df5 = df5.sort_values(by = ['ID','Frame_num','Centroid_X'])\n",
        "      df5['Centroid_X_diff'] = abs(df5.groupby(['ID'])['Centroid_X'].diff().fillna(0))\n",
        "      df5['Centroid_Y_diff'] = abs(df5.groupby(['ID'])['Centroid_Y'].diff().fillna(0))\n",
        "      df5['Total_Centroid_diff'] = (df5['Centroid_X_diff'] + df5['Centroid_Y_diff'])\n",
        "      df5['Total_Centroid_diff_cm'] = (df5['Total_Centroid_diff']/pixels_per_centimeter)\n",
        "      df10293847123948712349812374981234['Centroid_X_total_diff'] = df5.groupby(['ID'])['Centroid_X_diff'].sum()\n",
        "      df10293847123948712349812374981234['Centroid_Y_total_diff'] = df5.groupby(['ID'])['Centroid_Y_diff'].sum()\n",
        "      df10293847123948712349812374981234['Total_Diff'] = df10293847123948712349812374981234['Centroid_X_total_diff'] + df10293847123948712349812374981234['Centroid_Y_total_diff']\n",
        "      df10293847123948712349812374981234['Total_Diff_cm'] = (df10293847123948712349812374981234['Total_Diff'])/pixels_per_centimeter\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Surface area:\n",
        "      #Calculating Surface area of an ID over timeframe _x_:\n",
        "      Total_Area = []\n",
        "      for u in range(len(df5432['Masks0'])):\n",
        "        xy = df5432['Masks0'][u]\n",
        "        x, y = zip(*xy)\n",
        "        area = area_by_shoelace(x, y)\n",
        "        Total_Area.append(area)\n",
        "      df84646 = pd.DataFrame(Total_Area, columns = ['Total_Area'])\n",
        "      df5 = pd.concat([df5,df84646],axis=1)\n",
        "\n",
        "      Total_Area_Cm2 = []\n",
        "      for h in range(len(df5['Total_Area'])):\n",
        "        cm2 = (df5['Total_Area'][h])/(pixels_per_centimeter*pixels_per_centimeter)\n",
        "        Total_Area_Cm2.append(cm2)\n",
        "\n",
        "      df498149148 = pd.DataFrame(Total_Area_Cm2, columns = ['Total_Area_cm^2'])\n",
        "      df5 = pd.concat([df5,df498149148],axis=1)\n",
        "\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Counting # of Individuals in each of the Polygons for Each Frame:\n",
        "\n",
        "      Polygon1 = []\n",
        "      Polygon2 = []\n",
        "      Polygon3 = []\n",
        "      if \"coords1\" in locals():\n",
        "        for p in range(len(df5)):\n",
        "          point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "          polygon1 = Polygon(coords1)\n",
        "          Polygon1.append((polygon1.contains(point)))\n",
        "        dfpolygon1 = pd.DataFrame(Polygon1, columns = ['Polygon1'])\n",
        "        df5 = pd.concat([df5,dfpolygon1], axis = 1)\n",
        "\n",
        "      if \"coords2\" in locals():\n",
        "        for p in range(len(df5)):\n",
        "          point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "          polygon2 = Polygon(coords2)\n",
        "          Polygon2.append((polygon2.contains(point)))\n",
        "        dfpolygon2 = pd.DataFrame(Polygon2, columns = ['Polygon2'])\n",
        "        df5 = pd.concat([df5,dfpolygon2], axis = 1)\n",
        "\n",
        "      if \"coords3\" in locals():\n",
        "        for p in range(len(df5)):\n",
        "          point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "          polygon3 = Polygon(coords3)\n",
        "          Polygon3.append((polygon3.contains(point)))\n",
        "        dfpolygon3 = pd.DataFrame(Polygon3, columns = ['Polygon3'])\n",
        "        df5 = pd.concat([df5,dfpolygon3], axis = 1)\n",
        "\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: Counting Individuals:\n",
        "\n",
        "      # df456789 = pd.DataFrame(n, columns = ['Object_Counts'])\n",
        "\n",
        "      #______________________________________________________________________#____________________________________________________#: CHILL COMA RECOVERY:\n",
        "\n",
        "      #Create the data frame for movement over max_n frames:\n",
        "\n",
        "      max_n = 1800  # Rolling Window Frame\n",
        "      threshold = 700 # Locomotor Activity Threshold (pixels)\n",
        "\n",
        "      df5['Cumulative_Sum_Of_Movement'] = df5.groupby('ID')['Total_Centroid_diff'].transform(lambda x: x.rolling(window=max_n, min_periods=1).sum())\n",
        "      df5['Movement_Threshold'] = (df5['Cumulative_Sum_Of_Movement'] >= threshold).astype(int)\n",
        "\n",
        "      #Filter and data-frame the data to see what is the earliest frame at which certain motility threshold has been reached:\n",
        "\n",
        "      filtered_df5 = df5[df5['Movement_Threshold'] == 1]\n",
        "      CCR_df = filtered_df5.groupby('ID')['Frame_num'].min().reset_index()\n",
        "      print(CCR_df)\n",
        "\n",
        "      #Remove any columns under a certain frame threshold:\n",
        "      #df5 = df5.groupby('ID').filter(lambda x : len(x) > 500)\n",
        "\n",
        "      #Expose the dataframe:\n",
        "      df5.sort_values('ID')\n",
        "      print(df5.groupby(['ID']).count())\n",
        "\n",
        "      #Expose the dataframe:\n",
        "      df10293847123948712349812374981234.sort_values('ID')\n",
        "      print(df10293847123948712349812374981234.groupby(['ID']).count())\n",
        "\n",
        "      video_filename = os.path.basename(file_path)\n",
        "      video_name, _ = os.path.splitext(video_filename)\n",
        "      Total_csv_file_path = os.path.join(root, f'{video_name}_Total.csv')\n",
        "      Net_csv_file_path = os.path.join(root, f'{video_name}_Net.csv')\n",
        "\n",
        "      #Total_csv_file_path = os.path.join(root, f'{parent_directory}_Total.csv')\n",
        "      #Net_csv_file_path = os.path.join(root, f'{parent_directory}_Net.csv')\n",
        "\n",
        "      #Save the _main_dataframe:\n",
        "      df5.to_csv(Total_csv_file_path)\n",
        "\n",
        "      #Save the _net_dataframe:\n",
        "      df10293847123948712349812374981234.to_csv(Net_csv_file_path)\n",
        "\n",
        "      #Save _Object_Count DataFrame:\n",
        "      # df456789.to_csv('_object_count_filename.csv')\n",
        "\n",
        "      #Save CCR DataFrame:\n",
        "      # CCR_df.to_csv('/content/drive/MyDrive/ChillComaRecovery/TheOneIPracticed/Data/_CCR_.csv')\n",
        "\n",
        "\n",
        "def get_random_frame(folder_path):\n",
        "    # List all video files in the folder (common video formats)\n",
        "    video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\", \".flv\", \".wmv\", \".webm\", \".MOV\", \".MP4\",\".AVI\"]\n",
        "    video_files = [file for file in os.listdir(folder_path) if any(file.endswith(ext) for ext in video_extensions)]\n",
        "\n",
        "    if not video_files:\n",
        "        print(\"No video files found in the folder.\")\n",
        "        return None\n",
        "\n",
        "    # Choose a random video file\n",
        "    random_video_file = random.choice(video_files)\n",
        "\n",
        "    # Path to the chosen video file\n",
        "    video_file_path = os.path.join(folder_path, random_video_file)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error opening video file: {video_file_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Choose a random frame index\n",
        "    random_frame_index = random.randint(0, total_frames - 1)\n",
        "\n",
        "    # Set the frame position\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_index)\n",
        "\n",
        "    # Read the frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame is read correctly\n",
        "    if ret:\n",
        "        # Convert frame to RGB (OpenCV reads in BGR)\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        return frame_rgb\n",
        "    else:\n",
        "        print(f\"Error reading frame {random_frame_index} from {random_video_file}\")\n",
        "        return None\n",
        "\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL SELECTION AND TRAINING**"
      ],
      "metadata": {
        "id": "QWhLAng7xzFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Upload your Roboflow code and install your annotated data**"
      ],
      "metadata": {
        "id": "RwDHFfi-vegr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Test Code\")\n",
        "project = rf.workspace(\"Test Code\").project(\"Test Code\")\n",
        "dataset = project.version(0).download(\"Test Code\")"
      ],
      "metadata": {
        "id": "BX3Ivxt4s9QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train your model**"
      ],
      "metadata": {
        "id": "0-uLUVoQvnla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select model & Train it\n",
        "modell = YOLO('Model of Your Choice')\n",
        "modell.train(data = \"Insert Your Data.yaml in your training-data-set folder\", epochs = 100, imgsz= [w, h], batch = 5, project = \"Directory to Output the Model\")"
      ],
      "metadata": {
        "id": "IO3j-9j_xvOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Automatic Video Analysis:**\n",
        "\n",
        "____"
      ],
      "metadata": {
        "id": "D8X67o1GeGLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Calculate pixel per centimeter metric for MLDAAPP conversions**"
      ],
      "metadata": {
        "id": "d5F7t_rstN1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define your video directory:\n",
        "directory_path = 'Directory/To/Your/Videos'\n",
        "image = get_random_frame(directory_path)\n",
        "\n",
        "#Draw a line to calculate the pixel per centimeter variable for MLDAAPP conversions\n",
        "draw_lines(image,0,0,0,0) #x1,y1,x2,y2"
      ],
      "metadata": {
        "id": "AuJLF0WzrIvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run Video Analysis:**"
      ],
      "metadata": {
        "id": "Wy1UGxRgtXGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"Directory/To/best.pt\")\n",
        "pixels_per_centimeter = 144 #IMPORTANT: Define this variable from your own calculation\n",
        "\n",
        "directory_path = 'Directory/To/Your/Videos'\n",
        "\n",
        "# Recursively search for .MOV files\n",
        "for root, dirs, files in os.walk(directory_path):\n",
        "    for filename in files:\n",
        "        if filename.endswith('.MOV'):  #IMPORTANT: Modify .MOV with your video format\n",
        "            # Get the full path to the file\n",
        "            file_path = os.path.join(root, filename)\n",
        "\n",
        "            file_dir = os.path.dirname(file_path)\n",
        "\n",
        "            # Get the name of the parent directory\n",
        "            parent_directory = os.path.basename(root)\n",
        "\n",
        "            process_file(file_path, parent_directory)"
      ],
      "metadata": {
        "id": "UEcVJD4-eOTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Photo Analysis:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ikybQvh_K2YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run the model on your data and save to .csv**"
      ],
      "metadata": {
        "id": "Ux6ogRKmLp9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select your Custom Trained Model:\n",
        "model = YOLO(\"Your best.pt file directory\")\n",
        "\n",
        "#Run the model to extract the counts from each photo.\n",
        "n = []\n",
        "results = model.predict(\"Your Photo Data Folder\", save = True, conf = 0.32, show_labels=False) #IMPORTANT: Change Your Photo Data Folder to your Photo folder directory!\n",
        "\n",
        "for result in results:\n",
        "  boxes = result.boxes\n",
        "  masks = result.masks\n",
        "  keypoints = result.keypoints\n",
        "  probs = result.probs\n",
        "  n.append(len(boxes))\n",
        "\n",
        "#Save your data to a .csv file\n",
        "save_to_csv(\"FileName.csv\", \"ColumnName\", n) #IMPORTANT: Change the name opf FIleName.csv to your preferred file name, and change ColumnName to your preferred column name."
      ],
      "metadata": {
        "id": "-H82JmUCLGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Manual Video Analysis:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bJquvCpoLNES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**VIDEO EDITING**"
      ],
      "metadata": {
        "id": "fDs9dYv9xwBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_editing(\"Video Directory\",t0 = 0, t1=10, fps = 30, spd=1, w = 1920)\n",
        "frame = global_video"
      ],
      "metadata": {
        "id": "4jqYEfmyiZAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Usage**"
      ],
      "metadata": {
        "id": "B3GuyWsv7GGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set your video directory as frame variable if video_editing was not used:\n",
        "\n",
        "# frame = 'Test Video Directory'\n",
        "\n",
        "#Set empty data arrays to import model extracted data into:\n",
        "ID = []\n",
        "Names = []\n",
        "XYXY = []\n",
        "Masks = []\n",
        "Num_Frames = []\n",
        "n = []\n",
        "Class = []\n",
        "\n",
        "results = model.track(frame,tracker=\"/content/ultralytics/ultralytics/cfg/trackers/botsort.yaml\",save=True, persist = True, iou = 0.4, conf = 0.4, stream = True, save_conf = True)\n",
        "for results in results:\n",
        "  boxes = results.boxes\n",
        "  masks = results.masks\n",
        "  probs = results.probs\n",
        "  id = results.boxes.id\n",
        "  n.append(len(boxes))\n",
        "  for i in range(len(results)):\n",
        "    for x in range(len(results[i].boxes.xyxy.cpu().numpy())):\n",
        "      if ID is not None:\n",
        "        ID.append(results[i][x].boxes.id.cpu().numpy())\n",
        "      else:\n",
        "        pass\n",
        "      if XYXY is not None:\n",
        "        XYXY.append(results[i][x].boxes.xyxy.cpu().numpy())\n",
        "      else:\n",
        "        pass\n",
        "      if Masks is not None:\n",
        "        Masks.append(results[i][x].masks.xy)\n",
        "      else:\n",
        "        pass\n",
        "      if Names is not None:\n",
        "        Names.append(results[i][x].names)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "#Set the analyzed video as a photo frame to draw on:\n",
        "algimg = results[0].orig_img\n"
      ],
      "metadata": {
        "id": "w0B3m1zwidq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Drawing on the image**"
      ],
      "metadata": {
        "id": "uNMSSwAj-9ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this block even if not needed, it feeds neccessary data to process Data Extraction block."
      ],
      "metadata": {
        "id": "uAOVXSgfJlwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_dots(algimg, 874,848) #keep algimg\n",
        "#                  x1  y1\n",
        "draw_lines(algimg,200,400,600,800) #keep algimg\n",
        "#                 x1 y1 x2 y2\n",
        "draw_polygons(algimg, #keep algimg\n",
        "              100,200,  #x1 y1\n",
        "              400,500,  #x2 y2\n",
        "              600,700,  #x3 y3\n",
        "              800,900)  #x4 y4\n",
        "# coords1 = [[100,200],[400,500],[600,700],[800,900]]\n",
        "#           x1  y1    x2  y2    x3  y3    x4  y4\n",
        "draw_polygons(algimg, #keep algimg\n",
        "              100,200,  #x1 y1\n",
        "              400,500,  #x2 y2\n",
        "              600,700,  #x3 y3\n",
        "              800,900)  #x4 y4\n",
        "# coords2 = [[101,201],[400,501],[600,701],[801,901]]\n",
        "#           x1  y1    x2  y2    x3  y3    x4  y4\n",
        "#IMPORTANT:\n",
        "#Set the conversions from pixeles >>> cm:\n",
        "pixels_per_centimeter = 144\n",
        "\n",
        "#Set the custom q point within space (recommend using draw_dots):\n",
        "# q = []"
      ],
      "metadata": {
        "id": "0y986ZczQyFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Extraction:**"
      ],
      "metadata": {
        "id": "HqlxiJ2sSisG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#______________________________________________________________________#____________________________________________________#Extract general information from ML algorithm:\n",
        "df = pd.DataFrame(ID, columns = [\"ID\"])\n",
        "df71234848 = np.vstack(Names)\n",
        "df71234848 = pd.DataFrame(df71234848, columns = ['Object_Name'])\n",
        "df2 = np.vstack(XYXY)\n",
        "df3 = pd.DataFrame(df2, columns = (\"X1\",\"Y1\",\"X2\",\"Y2\"))\n",
        "df5 = pd.concat([df,df3], axis = 1)\n",
        "df5432 = pd.DataFrame(Masks, columns = [\"Masks0\"])\n",
        "\n",
        "# df5 = pd.concat([df,df3,df5432], axis = 1)\n",
        "# If used segmentation model ^Un-hash this to add Mask Coordinates to your DataFrame, be careful as highly dimensional objects may cause issues in your output .csv file\n",
        "\n",
        "df5 = pd.concat([df71234848, df5], axis = 1)\n",
        "\n",
        "#_________________________________________________________________#____________________________________________________#Reassign IDs for _main_ dataframe:\n",
        "\n",
        "# #Remove uneeded columns/ids: (Always re-assign higher # > lower #)\n",
        "\n",
        "# Rename column #A into column #B:\n",
        "# df5['ID'] = df5['ID'].replace([465],[455])\n",
        "# df5['ID'] = df5['ID'].replace([375],[346])\n",
        "\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#Assign Frame Numbers:\n",
        "\n",
        "df5['Frame_num'] = df5.groupby(['ID']).cumcount()+1\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Distance away from point q\n",
        "#Object_ID centroid coordinate:\n",
        "Centroid = []\n",
        "for x in range(len(df5)):\n",
        "  Centroid.append([((df5['X1'][x]+df5['X2'][x])/2),((df5['Y1'][x]+df5['Y2'][x])/2)])\n",
        "\n",
        "Centroid_df = pd.DataFrame(Centroid, columns = ['Centroid_X','Centroid_Y'])\n",
        "df5 = pd.concat([df5,Centroid_df],axis=1)\n",
        "\n",
        "#Object_ID distance away from point q:\n",
        "\n",
        "distance = []\n",
        "if \"q\" in locals():\n",
        "  for j in range(len(df5['Centroid_X'])):\n",
        "    distance.append(math.sqrt( ((df5['Centroid_X'][j]-q[0])**2)+((df5['Centroid_Y'][j]-q[1])**2)))\n",
        "  distance_df = pd.DataFrame(distance, columns = ['ID_Q_Distance'])\n",
        "  df5 = pd.concat([df5,distance_df], axis = 1)\n",
        "\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Distance away from initial position:\n",
        "\n",
        "#Adding Origin Distance to the correct ID:\n",
        "IDD_LIST = df5.ID.unique()\n",
        "Fly_ID_list = []\n",
        "Fly_ID_list.append(df5[df5['Frame_num'] == 1])\n",
        "Fly_ID_df = df5[['ID','Frame_num','Centroid_X','Centroid_Y']]\n",
        "Fly_ID_df = Fly_ID_df[Fly_ID_df['Frame_num'] == 1]\n",
        "Org_X = Fly_ID_df.Centroid_X.values.tolist()\n",
        "Org_Y = Fly_ID_df.Centroid_Y.values.tolist()\n",
        "centroid_origin = [(x, y) for x, y in zip(Org_X, Org_Y)]\n",
        "\n",
        "origin_index = 0\n",
        "for h in df5.ID.unique():\n",
        "    fly_df = df5[df5['ID'] == h]\n",
        "    for index, row in fly_df.iterrows():\n",
        "        df5.loc[index, 'Origin_X'] = centroid_origin[origin_index][0]\n",
        "        df5.loc[index, 'Origin_Y'] = centroid_origin[origin_index][1]\n",
        "    origin_index += 1\n",
        "\n",
        "orig_distance = []\n",
        "for j in range(len(df5['Centroid_X'])):\n",
        "  orig_distance.append(math.sqrt( ((df5['Centroid_X'][j]-df5['Origin_X'][j])**2)+((df5['Centroid_Y'][j]-df5['Origin_Y'][j])**2)))\n",
        "orig_distance_df = pd.DataFrame(orig_distance, columns = ['ID_Orig_Distance'])\n",
        "df5 = pd.concat([df5,orig_distance_df], axis = 1)\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Total Walk Distance by ID / Total Walk Distance by Frame:\n",
        "\n",
        "df10293847123948712349812374981234 = pd.DataFrame()\n",
        "df5 = df5.sort_values(by = ['ID','Frame_num','Centroid_X'])\n",
        "df5['Centroid_X_diff'] = abs(df5.groupby(['ID'])['Centroid_X'].diff().fillna(0))\n",
        "df5['Centroid_Y_diff'] = abs(df5.groupby(['ID'])['Centroid_Y'].diff().fillna(0))\n",
        "df5['Total_Centroid_diff'] = (df5['Centroid_X_diff'] + df5['Centroid_Y_diff'])\n",
        "df5['Total_Centroid_diff_cm'] = (df5['Total_Centroid_diff']/pixels_per_centimeter)\n",
        "df10293847123948712349812374981234['Centroid_X_total_diff'] = df5.groupby(['ID'])['Centroid_X_diff'].sum()\n",
        "df10293847123948712349812374981234['Centroid_Y_total_diff'] = df5.groupby(['ID'])['Centroid_Y_diff'].sum()\n",
        "df10293847123948712349812374981234['Total_Diff'] = df10293847123948712349812374981234['Centroid_X_total_diff'] + df10293847123948712349812374981234['Centroid_Y_total_diff']\n",
        "df10293847123948712349812374981234['Total_Diff_cm'] = (df10293847123948712349812374981234['Total_Diff'])/pixels_per_centimeter\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Surface area:\n",
        "#Calculating Surface area of an ID over timeframe _x_:\n",
        "Total_Area = []\n",
        "for u in range(len(df5432['Masks0'])):\n",
        "  xy = df5432['Masks0'][u]\n",
        "  x, y = zip(*xy)\n",
        "  area = area_by_shoelace(x, y)\n",
        "  Total_Area.append(area)\n",
        "df84646 = pd.DataFrame(Total_Area, columns = ['Total_Area'])\n",
        "df5 = pd.concat([df5,df84646],axis=1)\n",
        "\n",
        "Total_Area_Cm2 = []\n",
        "for h in range(len(df5['Total_Area'])):\n",
        "  cm2 = (df5['Total_Area'][h])/(pixels_per_centimeter*pixels_per_centimeter)\n",
        "  Total_Area_Cm2.append(cm2)\n",
        "\n",
        "df498149148 = pd.DataFrame(Total_Area_Cm2, columns = ['Total_Area_cm^2'])\n",
        "df5 = pd.concat([df5,df498149148],axis=1)\n",
        "\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Counting # of Individuals in each of the Polygons for Each Frame:\n",
        "\n",
        "Polygon1 = []\n",
        "Polygon2 = []\n",
        "Polygon3 = []\n",
        "if \"coords1\" in locals():\n",
        "  for p in range(len(df5)):\n",
        "    point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "    polygon1 = Polygon(coords1)\n",
        "    Polygon1.append((polygon1.contains(point)))\n",
        "  dfpolygon1 = pd.DataFrame(Polygon1, columns = ['Polygon1'])\n",
        "  df5 = pd.concat([df5,dfpolygon1], axis = 1)\n",
        "\n",
        "if \"coords2\" in locals():\n",
        "  for p in range(len(df5)):\n",
        "    point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "    polygon2 = Polygon(coords2)\n",
        "    Polygon2.append((polygon2.contains(point)))\n",
        "  dfpolygon2 = pd.DataFrame(Polygon2, columns = ['Polygon2'])\n",
        "  df5 = pd.concat([df5,dfpolygon2], axis = 1)\n",
        "\n",
        "if \"coords3\" in locals():\n",
        "  for p in range(len(df5)):\n",
        "    point = Point(df5['Centroid_X'][p],df5['Centroid_Y'][p])\n",
        "    polygon3 = Polygon(coords3)\n",
        "    Polygon3.append((polygon3.contains(point)))\n",
        "  dfpolygon3 = pd.DataFrame(Polygon3, columns = ['Polygon3'])\n",
        "  df5 = pd.concat([df5,dfpolygon3], axis = 1)\n",
        "\n",
        "\n",
        "#______________________________________________________________________#____________________________________________________#: Counting Individuals:\n",
        "# df456789 = pd.DataFrame(n, columns = ['Object_Counts'])\n",
        "\n",
        "\n",
        "\n",
        "#_______________________________________________________Remove any specific ID\n",
        "# df5 = df5[df5['ID'] != 417] #Remove any specific ID\n",
        "\n",
        "\n",
        "\n",
        "#______________________________________________________Remove any columns under a certain frame threshold:\n",
        "# df5 = df5.groupby('ID').filter(lambda x : len(x) > 500)\n",
        "\n",
        "\n",
        "\n",
        "#_____________________Expose the dataframe:\n",
        "df5.sort_values('ID')\n",
        "print(df5.groupby(['ID']).count())\n",
        "\n",
        "#___________________________________________________Expose the dataframe:\n",
        "df10293847123948712349812374981234.sort_values('ID')\n",
        "print(df10293847123948712349812374981234.groupby(['ID']).count())"
      ],
      "metadata": {
        "id": "nCjczPfrAGVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save the DataFrames to .csv Files:**"
      ],
      "metadata": {
        "id": "DeRsCu35jPyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the _main_dataframe:\n",
        "df5.to_csv('directory/_main_filename.csv')\n",
        "\n",
        "#Save the _net_dataframe:\n",
        "df10293847123948712349812374981234.to_csv('directory/_net_filename.csv')\n",
        "\n",
        "#Save _Object_Count DataFrame:\n",
        "df456789.to_csv('directory/_object_count_filename.csv')"
      ],
      "metadata": {
        "id": "B0xIwLk7FG_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}